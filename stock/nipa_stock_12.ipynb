{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nipa_stock_12.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNys5A6f3wcgwML7znadYF1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minicks/nipa/blob/master/stock/nipa_stock_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVs7btxYD7fQ",
        "colab_type": "text"
      },
      "source": [
        "Keras를 이용한 딥러닝 수행\n",
        "주가예측 딥러닝 모델 제작 프로세스를 따라가보는 과정입니다.\n",
        "사용된 패키지, 함수 등 모든 과정을 이해하려고 부담 갖지 않으셔도 됩니다.\n",
        "\n",
        "함수 및 라이브러리에 대한 자세한 설명은 선택과정에서 배울 수 있습니다.\n",
        "\n",
        "지금까지 우리는 주식 데이터 전처리를 진행해왔습니다. 이제 드디어 이 데이터와 Keras라는 라이브러리로 딥러닝 모델 학습을 진행해보도록 하겠습니다.\n",
        "\n",
        "Keras는 최근 가장 많이 사용되는 딥러닝 라이브러리 중 하나로 딥러닝을 구현하는데 필요한 많은 함수와 기능들을 가지고 있습니다.\n",
        "\n",
        "많은 개발자 분들의 노력 덕분에, 우리는 Keras 라이브러리를 불러오기만 하는 것으로 딥러닝을 바로 적용해볼 수 있는 것이죠.\n",
        "\n",
        "딥러닝 모델 학습은 다음과 같이 진행됩니다.\n",
        "\n",
        "전처리된 데이터를 준비\n",
        "Keras 모델을 생성\n",
        "전처리된 데이터를 Keras 모델에 입력\n",
        "Keras 모델이 입력된 데이터를 학습\n",
        "바로 해볼까요?\n",
        "\n",
        "지시사항\n",
        "이 문제는 별도 제출이 필요 없는 실습입니다.\n",
        "\n",
        "미리 만들어진 코드의 주석과 의미를 확인합니다.\n",
        "실행 버튼을 눌러 각 코드의 실행 결과를 확인해보세요.\n",
        "Keras 라이브러리를 통해 학습이 어떻게 진행되는지를 확인해보세요.\n",
        "Tips\n",
        "실습에 포함된 학습 파라미터는 다음과 같습니다.\n",
        "\n",
        "learning_rate(학습률): 학습 효율을 얼마나 좋게 할 것인지를 설정합니다. 효율이 크면 좋을 것 같지만, 이 경우 모델이 특정 데이터셋만 과하게 학습하기 때문에 모델이 보지 못한 새로운 데이터가 나타났을 때 제대로 예측하지 못합니다.\n",
        "training_cnt(반복횟수): 학습을 얼마나 오래 반복할 것인지를 설정합니다. 일반적으로 학습을 오래 반복할 수록 성능이 좋아지지만, 그만큼 학습 시간이 길어집니다.\n",
        "batch_size(회당 학습량): 한 번에 얼마나 많은 데이터를 학습할지를 설정합니다. 높을 수록 좋지만, 그만큼 더 많은 컴퓨터 성능을 요구하며 학습 속도가 느려집니다.\n",
        "각 학습 파라미터가 무엇인지, 어떻게 설정해야 하는지를 세세하게 알 필요는 없으며, 지금 단계에서는 이런 것이 있구나 정도로 알아두고 계시는 것으로 충분합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB89yE2oD6di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras import models # Keras 라이브러리를 불러옵니다\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Dense, Activation\n",
        "from elice_utils import EliceUtils\n",
        "elice_utils = EliceUtils()\n",
        "\n",
        "\n",
        "\n",
        "# --- 주식 데이터 로드, 전처리, 분할하기(이전 실습에서 진행) --- #\n",
        "df = pd.read_csv('stock.csv') \n",
        "\n",
        "# 주가의 중간값 계산하기\n",
        "high_prices = df['High'].values\n",
        "low_prices = df['Low'].values\n",
        "mid_prices = (high_prices + low_prices) / 2\n",
        "\n",
        "# 주가 데이터에 중간 값 요소 추가하기\n",
        "df['Mid'] = mid_prices\n",
        "\n",
        "# 종가의 5일 이동평균값을 계산하고 주가 데이터에 추가하기\n",
        "ma5 = df['Adj Close'].rolling(window=5).mean()\n",
        "df['MA5'] = ma5\n",
        "\n",
        "df = df.fillna(0) # 비어있는 값을 모두 0으로 바꾸기\n",
        "\n",
        "# Date 열를 제거합니다.\n",
        "df = df.drop('Date', axis = 1)\n",
        "\n",
        "# 데이터 스케일링(MinMaxScaler 적용)\n",
        "min_max_scaler = MinMaxScaler()\n",
        "fitted = min_max_scaler.fit(df)\n",
        "\n",
        "output = min_max_scaler.transform(df)\n",
        "output = pd.DataFrame(output, columns=df.columns, index=list(df.index.values))\n",
        "\n",
        "# 트레인셋/테스트셋 크기 설정\n",
        "train_size = int(len(output)* 0.6) # 트레인셋은 전체의 60%\n",
        "test_size = int(len(output)*0.3) + train_size # 테스트셋은 전체의 30%\n",
        "\n",
        "#train/test 학습 및 라벨 설정\n",
        "#종가를 예측하기 위해 종가를 label로 설정\n",
        "train_x = np.array(output[:train_size])\n",
        "train_y = np.array(output['Close'][:train_size])\n",
        "test_x =np.array(output[train_size:test_size])\n",
        "test_y = np.array(output['Close'][train_size:test_size])\n",
        "validation_x = np.array(output[test_size:])\n",
        "validation_y = np.array(output['Close'][test_size:])\n",
        "\n",
        "\n",
        "\n",
        "# --- Keras를 이용한 딥러닝 수행 --- #\n",
        "\n",
        "model = Sequential() # Keras 모델을 생성합니다.\n",
        "\n",
        "# Keras 딥러닝 모델 학습을 위한 파라미터(옵션값)을 설정합니다.\n",
        "# 현재 단계에서 각 파라미터에 대한 세부적인 내용까지 알 필요는 없으므로, 너무 걱정하지 마세요.\n",
        "learning_rate = 0.01\n",
        "training_cnt = 1000\n",
        "batch_size = 100 \n",
        "input_size = 8 \n",
        "\n",
        "# 생성된 딥러닝 모델에 학습용 데이터(train_x)를 넣습니다.\n",
        "# 마찬가지로 구체적인 코드를 처음부터 모두 이해하고 외울 필요는 없습니다.\n",
        "model.add(Dense(input_size, activation='tanh', input_shape=(train_x.shape[1],))) \n",
        "model.add(Dense(input_size * 3,  activation='tanh')) \n",
        "model.add(Dense(1, activation='tanh'))\n",
        "\n",
        "# 데이터를 학습을 진행합니다.\n",
        "model.compile(optimizer='sgd', loss='mse', metrics=['mae', 'mape','acc'])\n",
        "model.summary()\n",
        "history = model.fit(train_x, train_y, epochs=training_cnt,   \n",
        "                    batch_size=batch_size, verbose=1)\n",
        "val_mse, val_mae, val_mape, val_acc = model.evaluate(test_x, test_y, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}